{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing in Business Contexts\n",
    "\n",
    "**Module: Descriptive & Inferential Statistics**\n",
    "\n",
    "## Learning Objectives\n",
    "- Design and set up A/B tests\n",
    "- Calculate required sample sizes\n",
    "- Analyze A/B test results for statistical significance\n",
    "- Interpret results and make business recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick Refresher\n",
    "\n",
    "### A/B Test Components\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **Control (A)** | Current version, baseline |\n",
    "| **Treatment (B)** | New version being tested |\n",
    "| **Metric** | What you're measuring (conversion rate, revenue, etc.) |\n",
    "| **Sample size** | Number of users per group |\n",
    "| **Duration** | How long to run the test |\n",
    "\n",
    "### Key Concepts\n",
    "- **Minimum Detectable Effect (MDE)**: Smallest improvement worth detecting\n",
    "- **Statistical Power**: Probability of detecting a real effect (typically 80%)\n",
    "- **Significance Level (α)**: Probability of false positive (typically 5%)\n",
    "- **Practical Significance**: Is the effect size meaningful for the business?\n",
    "\n",
    "### Common Pitfalls\n",
    "- Peeking at results early and stopping when significant\n",
    "- Running tests too short (novelty effects)\n",
    "- Not accounting for multiple comparisons\n",
    "- Ignoring segment differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sample Size Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_size_proportion(p1, p2, alpha=0.05, power=0.80):\n",
    "    \"\"\"\n",
    "    Calculate required sample size per group for comparing two proportions.\n",
    "    \n",
    "    p1: baseline conversion rate\n",
    "    p2: expected conversion rate with treatment\n",
    "    alpha: significance level (Type I error rate)\n",
    "    power: 1 - Type II error rate\n",
    "    \"\"\"\n",
    "    # Z-scores\n",
    "    z_alpha = stats.norm.ppf(1 - alpha/2)  # Two-tailed\n",
    "    z_beta = stats.norm.ppf(power)\n",
    "    \n",
    "    # Pooled proportion\n",
    "    p_pooled = (p1 + p2) / 2\n",
    "    \n",
    "    # Sample size formula\n",
    "    n = (2 * p_pooled * (1 - p_pooled) * (z_alpha + z_beta)**2) / (p2 - p1)**2\n",
    "    \n",
    "    return int(np.ceil(n))\n",
    "\n",
    "# Example: Testing a checkout page\n",
    "# Current conversion: 3%\n",
    "# Want to detect if new version achieves 3.5% (0.5% absolute lift)\n",
    "\n",
    "baseline = 0.03\n",
    "expected = 0.035\n",
    "n_per_group = sample_size_proportion(baseline, expected)\n",
    "\n",
    "print(f\"Baseline conversion: {baseline*100}%\")\n",
    "print(f\"Expected conversion: {expected*100}%\")\n",
    "print(f\"Minimum detectable effect: {(expected-baseline)*100}% absolute\")\n",
    "print(f\"\\nRequired sample size per group: {n_per_group:,}\")\n",
    "print(f\"Total sample size: {n_per_group*2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How MDE affects sample size\n",
    "print(\"MDE (absolute) | Sample Size per Group\")\n",
    "print(\"-\" * 40)\n",
    "for mde in [0.001, 0.002, 0.005, 0.01, 0.02]:\n",
    "    n = sample_size_proportion(baseline, baseline + mde)\n",
    "    print(f\"    {mde*100:.1f}%       |     {n:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Working Example: E-commerce Checkout A/B Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate A/B test data\n",
    "np.random.seed(42)\n",
    "\n",
    "n_control = 5000\n",
    "n_treatment = 5000\n",
    "\n",
    "# True conversion rates (in real life, you don't know treatment rate)\n",
    "true_control_rate = 0.032\n",
    "true_treatment_rate = 0.038\n",
    "\n",
    "# Generate data\n",
    "control_conversions = np.random.binomial(1, true_control_rate, n_control)\n",
    "treatment_conversions = np.random.binomial(1, true_treatment_rate, n_treatment)\n",
    "\n",
    "# Create DataFrame\n",
    "ab_data = pd.DataFrame({\n",
    "    'group': ['control'] * n_control + ['treatment'] * n_treatment,\n",
    "    'converted': np.concatenate([control_conversions, treatment_conversions])\n",
    "})\n",
    "\n",
    "ab_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "summary = ab_data.groupby('group')['converted'].agg(['sum', 'count', 'mean'])\n",
    "summary.columns = ['conversions', 'visitors', 'conversion_rate']\n",
    "summary['conversion_rate_pct'] = summary['conversion_rate'] * 100\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract values for analysis\n",
    "control = ab_data[ab_data['group'] == 'control']['converted']\n",
    "treatment = ab_data[ab_data['group'] == 'treatment']['converted']\n",
    "\n",
    "n_c, conv_c = len(control), control.sum()\n",
    "n_t, conv_t = len(treatment), treatment.sum()\n",
    "p_c = conv_c / n_c\n",
    "p_t = conv_t / n_t\n",
    "\n",
    "print(f\"Control: {conv_c}/{n_c} = {p_c*100:.2f}%\")\n",
    "print(f\"Treatment: {conv_t}/{n_t} = {p_t*100:.2f}%\")\n",
    "print(f\"\\nAbsolute difference: {(p_t - p_c)*100:.2f}%\")\n",
    "print(f\"Relative lift: {(p_t - p_c)/p_c*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Significance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab_test_proportions(conversions_a, total_a, conversions_b, total_b):\n",
    "    \"\"\"\n",
    "    Perform z-test for comparing two proportions.\n",
    "    Returns z-statistic, p-value, and confidence interval for difference.\n",
    "    \"\"\"\n",
    "    # Proportions\n",
    "    p_a = conversions_a / total_a\n",
    "    p_b = conversions_b / total_b\n",
    "    \n",
    "    # Pooled proportion under H0\n",
    "    p_pooled = (conversions_a + conversions_b) / (total_a + total_b)\n",
    "    \n",
    "    # Standard error\n",
    "    se = np.sqrt(p_pooled * (1 - p_pooled) * (1/total_a + 1/total_b))\n",
    "    \n",
    "    # Z-statistic\n",
    "    z = (p_b - p_a) / se\n",
    "    \n",
    "    # Two-tailed p-value\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "    \n",
    "    # 95% CI for difference (using unpooled SE)\n",
    "    se_diff = np.sqrt(p_a*(1-p_a)/total_a + p_b*(1-p_b)/total_b)\n",
    "    ci_lower = (p_b - p_a) - 1.96 * se_diff\n",
    "    ci_upper = (p_b - p_a) + 1.96 * se_diff\n",
    "    \n",
    "    return {\n",
    "        'z_statistic': z,\n",
    "        'p_value': p_value,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'significant': p_value < 0.05\n",
    "    }\n",
    "\n",
    "results = ab_test_proportions(conv_c, n_c, conv_t, n_t)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"A/B TEST RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Z-statistic: {results['z_statistic']:.3f}\")\n",
    "print(f\"P-value: {results['p_value']:.4f}\")\n",
    "print(f\"95% CI for difference: ({results['ci_lower']*100:.2f}%, {results['ci_upper']*100:.2f}%)\")\n",
    "print(f\"\\nStatistically significant at α=0.05: {'Yes ✓' if results['significant'] else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Using scipy's chi-squared test\n",
    "contingency_table = pd.crosstab(ab_data['group'], ab_data['converted'])\n",
    "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"Chi-squared test:\")\n",
    "print(f\"χ² = {chi2:.3f}, p = {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the impact\n",
    "monthly_visitors = 100000\n",
    "avg_order_value = 75  # dollars\n",
    "\n",
    "# Current monthly conversions and revenue\n",
    "current_conversions = monthly_visitors * p_c\n",
    "current_revenue = current_conversions * avg_order_value\n",
    "\n",
    "# Projected with treatment\n",
    "projected_conversions = monthly_visitors * p_t\n",
    "projected_revenue = projected_conversions * avg_order_value\n",
    "\n",
    "# Uplift\n",
    "additional_conversions = projected_conversions - current_conversions\n",
    "additional_revenue = projected_revenue - current_revenue\n",
    "\n",
    "print(\"PROJECTED MONTHLY IMPACT\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Additional conversions: {additional_conversions:,.0f}\")\n",
    "print(f\"Additional revenue: ${additional_revenue:,.0f}\")\n",
    "print(f\"Annual revenue impact: ${additional_revenue * 12:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Sample Size Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You're planning an A/B test for a sign-up form.\n",
    "# Current sign-up rate: 12%\n",
    "# You want to detect a 1.5% absolute improvement (to 13.5%)\n",
    "\n",
    "# TODO: Calculate the required sample size per group\n",
    "# Use alpha=0.05 and power=0.80\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your website gets 2,000 visitors per day.\n",
    "# If you split traffic 50/50, how many days do you need to run the test?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Marketing says they can only wait 2 weeks.\n",
    "# What's the minimum detectable effect you can achieve in that time?\n",
    "# Hint: Work backwards - with 14 days * 1000 per group, what MDE is possible?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Analyze A/B Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email subject line A/B test results\n",
    "email_test = pd.DataFrame({\n",
    "    'variant': ['Subject A', 'Subject B'],\n",
    "    'emails_sent': [15000, 15000],\n",
    "    'opens': [2850, 3150]\n",
    "})\n",
    "\n",
    "email_test['open_rate'] = email_test['opens'] / email_test['emails_sent']\n",
    "print(email_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the absolute and relative difference in open rates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test if the difference is statistically significant at α = 0.05\n",
    "# Calculate the z-statistic and p-value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the 95% confidence interval for the difference in open rates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a brief recommendation: Should we switch to Subject B?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Full A/B Test Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landing page A/B test with user-level data\n",
    "np.random.seed(123)\n",
    "\n",
    "landing_test = pd.DataFrame({\n",
    "    'user_id': range(1, 20001),\n",
    "    'variant': np.random.choice(['original', 'new_design'], 20000),\n",
    "    'device': np.random.choice(['mobile', 'desktop'], 20000, p=[0.6, 0.4]),\n",
    "})\n",
    "\n",
    "# Conversion depends on variant AND device\n",
    "def get_conversion(row):\n",
    "    if row['variant'] == 'original':\n",
    "        rate = 0.05 if row['device'] == 'mobile' else 0.08\n",
    "    else:\n",
    "        rate = 0.055 if row['device'] == 'mobile' else 0.095  # New design works better\n",
    "    return np.random.binomial(1, rate)\n",
    "\n",
    "landing_test['converted'] = landing_test.apply(get_conversion, axis=1)\n",
    "landing_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate overall conversion rates for each variant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test if the new design has significantly higher conversion (overall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Break down conversion rates by device type\n",
    "# Is the new design better on both mobile and desktop?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run separate significance tests for mobile and desktop users\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Continuous Metric A/B Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a new recommendation algorithm on average order value\n",
    "np.random.seed(456)\n",
    "\n",
    "# Control: current algorithm\n",
    "control_aov = np.random.normal(loc=85, scale=35, size=1000)\n",
    "control_aov = np.clip(control_aov, 10, 300)  # Realistic bounds\n",
    "\n",
    "# Treatment: new recommendation algorithm\n",
    "treatment_aov = np.random.normal(loc=92, scale=38, size=1000)\n",
    "treatment_aov = np.clip(treatment_aov, 10, 300)\n",
    "\n",
    "print(f\"Control: mean=${control_aov.mean():.2f}, std=${control_aov.std():.2f}\")\n",
    "print(f\"Treatment: mean=${treatment_aov.mean():.2f}, std=${treatment_aov.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test if the treatment has significantly higher average order value\n",
    "# Use a two-sample t-test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the 95% CI for the difference in mean AOV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate Cohen's d effect size\n",
    "# Is this a small, medium, or large effect?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: If you process 5,000 orders per month, estimate the monthly revenue impact\n",
    "# Include confidence bounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Multiple Variants Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing 3 different button colors (A/B/C test)\n",
    "button_test = pd.DataFrame({\n",
    "    'variant': ['Blue (Control)', 'Green', 'Orange'],\n",
    "    'visitors': [10000, 10000, 10000],\n",
    "    'clicks': [320, 380, 345]\n",
    "})\n",
    "\n",
    "button_test['ctr'] = button_test['clicks'] / button_test['visitors']\n",
    "print(button_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform chi-squared test to check if there's any difference among the three\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare Green vs Control (Blue) - is Green significantly better?\n",
    "# Note: When doing multiple comparisons, consider Bonferroni correction\n",
    "# Adjusted alpha = 0.05 / number of comparisons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Which button would you recommend, and why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 Solutions\n",
    "\n",
    "# Sample size calculation\n",
    "baseline_rate = 0.12\n",
    "target_rate = 0.135\n",
    "n = sample_size_proportion(baseline_rate, target_rate)\n",
    "print(f\"Required sample size per group: {n:,}\")\n",
    "\n",
    "# Days needed\n",
    "daily_visitors = 2000\n",
    "visitors_per_group_per_day = daily_visitors / 2\n",
    "days_needed = np.ceil(n / visitors_per_group_per_day)\n",
    "print(f\"Days needed: {days_needed:.0f}\")\n",
    "\n",
    "# MDE with 2-week constraint\n",
    "n_available = 14 * visitors_per_group_per_day\n",
    "print(f\"\\nWith 2 weeks, you have {n_available:.0f} visitors per group\")\n",
    "# Approximate MDE (would need to solve equation, but roughly):\n",
    "# For n=14000, MDE is approximately 1.8-2%\n",
    "print(\"MDE would be approximately 1.8-2% absolute (would need to solve iteratively)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Solutions\n",
    "\n",
    "# Differences\n",
    "p_a = 2850 / 15000\n",
    "p_b = 3150 / 15000\n",
    "abs_diff = p_b - p_a\n",
    "rel_diff = (p_b - p_a) / p_a * 100\n",
    "\n",
    "print(f\"Subject A open rate: {p_a*100:.2f}%\")\n",
    "print(f\"Subject B open rate: {p_b*100:.2f}%\")\n",
    "print(f\"Absolute difference: {abs_diff*100:.2f}%\")\n",
    "print(f\"Relative improvement: {rel_diff:.1f}%\")\n",
    "\n",
    "# Significance test\n",
    "results = ab_test_proportions(2850, 15000, 3150, 15000)\n",
    "print(f\"\\nZ-statistic: {results['z_statistic']:.3f}\")\n",
    "print(f\"P-value: {results['p_value']:.4f}\")\n",
    "print(f\"95% CI: ({results['ci_lower']*100:.2f}%, {results['ci_upper']*100:.2f}%)\")\n",
    "print(f\"\\nStatistically significant: {'Yes' if results['significant'] else 'No'}\")\n",
    "\n",
    "print(\"\\nRecommendation: Yes, switch to Subject B. The 2% absolute improvement is\")\n",
    "print(\"statistically significant and represents a meaningful 10.5% relative lift.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 Solutions\n",
    "\n",
    "# Overall conversion rates\n",
    "overall = landing_test.groupby('variant')['converted'].agg(['sum', 'count', 'mean'])\n",
    "print(\"Overall Results:\")\n",
    "print(overall)\n",
    "\n",
    "# Significance test\n",
    "orig = landing_test[landing_test['variant'] == 'original']\n",
    "new = landing_test[landing_test['variant'] == 'new_design']\n",
    "\n",
    "results = ab_test_proportions(\n",
    "    orig['converted'].sum(), len(orig),\n",
    "    new['converted'].sum(), len(new)\n",
    ")\n",
    "print(f\"\\nOverall test: p-value = {results['p_value']:.4f}\")\n",
    "print(f\"Significant: {results['significant']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown by device\n",
    "print(\"\\nBy Device:\")\n",
    "device_breakdown = landing_test.groupby(['device', 'variant'])['converted'].agg(['sum', 'count', 'mean'])\n",
    "print(device_breakdown)\n",
    "\n",
    "# Test for each device\n",
    "for device in ['mobile', 'desktop']:\n",
    "    subset = landing_test[landing_test['device'] == device]\n",
    "    orig_d = subset[subset['variant'] == 'original']\n",
    "    new_d = subset[subset['variant'] == 'new_design']\n",
    "    \n",
    "    res = ab_test_proportions(\n",
    "        orig_d['converted'].sum(), len(orig_d),\n",
    "        new_d['converted'].sum(), len(new_d)\n",
    "    )\n",
    "    print(f\"\\n{device.capitalize()}: p-value = {res['p_value']:.4f}, significant = {res['significant']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4 Solutions\n",
    "\n",
    "# T-test\n",
    "t_stat, p_value = stats.ttest_ind(treatment_aov, control_aov)\n",
    "print(f\"T-statistic: {t_stat:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Significant: {p_value < 0.05}\")\n",
    "\n",
    "# CI for difference\n",
    "mean_diff = treatment_aov.mean() - control_aov.mean()\n",
    "se_diff = np.sqrt(treatment_aov.var()/len(treatment_aov) + control_aov.var()/len(control_aov))\n",
    "ci = (mean_diff - 1.96*se_diff, mean_diff + 1.96*se_diff)\n",
    "print(f\"\\n95% CI for AOV difference: (${ci[0]:.2f}, ${ci[1]:.2f})\")\n",
    "\n",
    "# Cohen's d\n",
    "pooled_std = np.sqrt((treatment_aov.var() + control_aov.var()) / 2)\n",
    "d = mean_diff / pooled_std\n",
    "print(f\"\\nCohen's d: {d:.3f} (small effect)\")\n",
    "\n",
    "# Monthly impact\n",
    "monthly_orders = 5000\n",
    "expected_monthly_lift = mean_diff * monthly_orders\n",
    "ci_lower_monthly = ci[0] * monthly_orders\n",
    "ci_upper_monthly = ci[1] * monthly_orders\n",
    "print(f\"\\nMonthly revenue impact: ${expected_monthly_lift:,.0f}\")\n",
    "print(f\"95% CI: (${ci_lower_monthly:,.0f}, ${ci_upper_monthly:,.0f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5 Solutions\n",
    "\n",
    "# Chi-squared test\n",
    "contingency = np.array([[320, 10000-320], [380, 10000-380], [345, 10000-345]])\n",
    "chi2, p_value, dof, expected = stats.chi2_contingency(contingency)\n",
    "print(f\"Chi-squared test: χ² = {chi2:.2f}, p = {p_value:.4f}\")\n",
    "print(f\"There IS a significant difference among the three variants.\")\n",
    "\n",
    "# Green vs Control with Bonferroni correction\n",
    "# 3 comparisons: Blue-Green, Blue-Orange, Green-Orange\n",
    "bonferroni_alpha = 0.05 / 3\n",
    "print(f\"\\nBonferroni-corrected alpha: {bonferroni_alpha:.4f}\")\n",
    "\n",
    "green_vs_blue = ab_test_proportions(320, 10000, 380, 10000)\n",
    "print(f\"\\nGreen vs Blue:\")\n",
    "print(f\"  p-value: {green_vs_blue['p_value']:.4f}\")\n",
    "print(f\"  Significant at corrected alpha: {green_vs_blue['p_value'] < bonferroni_alpha}\")\n",
    "\n",
    "print(\"\\nRecommendation: Switch to Green button.\")\n",
    "print(\"- Green shows 18.75% relative improvement over Blue\")\n",
    "print(\"- The difference is significant even with Bonferroni correction\")\n",
    "print(\"- Orange improvement (7.8%) is smaller and may not be significant\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MFR    \n  Teaching",
   "language": "python",
   "name": "mfr-teaching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
