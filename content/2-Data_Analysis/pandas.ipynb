{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb93c42",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "Pandas is the most popular Python library for data analysis and manipulation. It provides high-performance, easy-to-use data structures and data analysis tools built on top of NumPy.\n",
    "\n",
    "The name \"pandas\" is derived from \"panel data\" - an econometrics term for multidimensional structured datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4b4a2",
   "metadata": {},
   "source": [
    "## Why Pandas?\n",
    "\n",
    "### Advantages:\n",
    "1. **Easy Data Handling**: Work with structured data intuitively\n",
    "2. **Data Cleaning**: Handle missing data, duplicates, and inconsistencies\n",
    "3. **Data Transformation**: Reshape, merge, join, and pivot data easily\n",
    "4. **Time Series**: Built-in support for time series data\n",
    "5. **Integration**: Works seamlessly with NumPy, Matplotlib, and other libraries\n",
    "6. **I/O Operations**: Read/write CSV, Excel, SQL, JSON, and more\n",
    "\n",
    "### Key Features:\n",
    "- DataFrame and Series data structures\n",
    "- Intelligent data alignment\n",
    "- Flexible grouping and aggregation\n",
    "- Built-in visualization\n",
    "- Efficient indexing and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aebdf0",
   "metadata": {},
   "source": [
    "## Installation and Import\n",
    "\n",
    "Install pandas if you haven't already:\n",
    "```bash\n",
    "pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas with the standard alias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check pandas version\n",
    "print(\"Pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54dcf07",
   "metadata": {},
   "source": [
    "## Core Data Structures\n",
    "\n",
    "Pandas has two main data structures:\n",
    "\n",
    "1. **Series**: One-dimensional labeled array (like a column)\n",
    "2. **DataFrame**: Two-dimensional labeled data structure (like a table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ebf1f7",
   "metadata": {},
   "source": [
    "## Pandas Series\n",
    "\n",
    "A Series is a one-dimensional array with labels (index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c60088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series from a list\n",
    "series_from_list = pd.Series([10, 20, 30, 40, 50])\n",
    "print(\"Series from list:\")\n",
    "print(series_from_list)\n",
    "print(\"\\nData type:\", type(series_from_list))\n",
    "\n",
    "# Create a Series with custom index\n",
    "series_with_index = pd.Series([10, 20, 30, 40, 50], \n",
    "                               index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(\"\\nSeries with custom index:\")\n",
    "print(series_with_index)\n",
    "\n",
    "# Create a Series from a dictionary\n",
    "data_dict = {'apple': 5, 'banana': 3, 'orange': 8}\n",
    "series_from_dict = pd.Series(data_dict)\n",
    "print(\"\\nSeries from dictionary:\")\n",
    "print(series_from_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697bff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series attributes and methods\n",
    "series = pd.Series([10, 20, 30, 40, 50], index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "print(\"Values:\", series.values)\n",
    "print(\"Index:\", series.index)\n",
    "print(\"Shape:\", series.shape)\n",
    "print(\"Size:\", series.size)\n",
    "print(\"Data type:\", series.dtype)\n",
    "\n",
    "# Accessing elements\n",
    "print(\"\\nAccess by index label:\", series['c'])\n",
    "print(\"Access by position:\", series[2])\n",
    "print(\"Access multiple:\", series[['a', 'c', 'e']])\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nMean:\", series.mean())\n",
    "print(\"Sum:\", series.sum())\n",
    "print(\"Max:\", series.max())\n",
    "print(\"Min:\", series.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5824fb9",
   "metadata": {},
   "source": [
    "## Pandas DataFrame\n",
    "\n",
    "A DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. Think of it as a spreadsheet or SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc66dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 32],\n",
    "    'City': ['New York', 'London', 'Paris', 'Tokyo', 'Berlin'],\n",
    "    'Salary': [50000, 60000, 55000, 65000, 58000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame from dictionary:\")\n",
    "print(df)\n",
    "\n",
    "# Create DataFrame from list of lists\n",
    "data_list = [\n",
    "    ['Alice', 25, 'New York', 50000],\n",
    "    ['Bob', 30, 'London', 60000],\n",
    "    ['Charlie', 35, 'Paris', 55000]\n",
    "]\n",
    "df_from_list = pd.DataFrame(data_list, \n",
    "                             columns=['Name', 'Age', 'City', 'Salary'])\n",
    "print(\"\\nDataFrame from list:\")\n",
    "print(df_from_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff127dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame attributes and methods\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumn names:\", df.columns.tolist())\n",
    "print(\"\\nIndex:\", df.index.tolist())\n",
    "print(\"\\nData types:\\n\", df.dtypes)\n",
    "print(\"\\nInfo:\")\n",
    "df.info()\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(df.head(3))\n",
    "print(\"\\nLast 2 rows:\")\n",
    "print(df.tail(2))\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5ffc6",
   "metadata": {},
   "source": [
    "## Selecting Data\n",
    "\n",
    "Pandas provides multiple ways to select and access data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [25, 30, 35, 28, 32],\n",
    "    'City': ['New York', 'London', 'Paris', 'Tokyo', 'Berlin'],\n",
    "    'Salary': [50000, 60000, 55000, 65000, 58000]\n",
    "})\n",
    "\n",
    "# Select single column (returns Series)\n",
    "print(\"Select 'Name' column:\")\n",
    "print(df['Name'])\n",
    "print(\"\\nType:\", type(df['Name']))\n",
    "\n",
    "# Select multiple columns (returns DataFrame)\n",
    "print(\"\\nSelect multiple columns:\")\n",
    "print(df[['Name', 'Age']])\n",
    "\n",
    "# Select rows by index position (iloc)\n",
    "print(\"\\nFirst row (iloc):\")\n",
    "print(df.iloc[0])\n",
    "\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(df.iloc[0:3])\n",
    "\n",
    "# Select rows by index label (loc)\n",
    "print(\"\\nSelect by label (loc):\")\n",
    "print(df.loc[1:3, ['Name', 'City']])\n",
    "\n",
    "# Select specific cells\n",
    "print(\"\\nSelect specific cell:\")\n",
    "print(df.loc[2, 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indexing (filtering)\n",
    "print(\"People older than 30:\")\n",
    "print(df[df['Age'] > 30])\n",
    "\n",
    "print(\"\\nPeople in New York or London:\")\n",
    "print(df[df['City'].isin(['New York', 'London'])])\n",
    "\n",
    "# Multiple conditions (AND)\n",
    "print(\"\\nAge > 25 AND Salary > 55000:\")\n",
    "print(df[(df['Age'] > 25) & (df['Salary'] > 55000)])\n",
    "\n",
    "# Multiple conditions (OR)\n",
    "print(\"\\nAge < 30 OR Salary > 60000:\")\n",
    "print(df[(df['Age'] < 30) | (df['Salary'] > 60000)])\n",
    "\n",
    "# String methods\n",
    "print(\"\\nNames starting with 'A' or 'B':\")\n",
    "print(df[df['Name'].str.startswith(('A', 'B'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d213ab",
   "metadata": {},
   "source": [
    "## Adding and Modifying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ffee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'Salary': [50000, 60000, 55000]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Add a new column\n",
    "df['City'] = ['New York', 'London', 'Paris']\n",
    "print(\"\\nAfter adding 'City' column:\")\n",
    "print(df)\n",
    "\n",
    "# Add calculated column\n",
    "df['Salary_k'] = df['Salary'] / 1000\n",
    "print(\"\\nAfter adding calculated column:\")\n",
    "print(df)\n",
    "\n",
    "# Modify existing column\n",
    "df['Age'] = df['Age'] + 1\n",
    "print(\"\\nAfter incrementing Age:\")\n",
    "print(df)\n",
    "\n",
    "# Add new row using loc\n",
    "df.loc[3] = ['David', 29, 65000, 'Tokyo', 65]\n",
    "print(\"\\nAfter adding new row:\")\n",
    "print(df)\n",
    "\n",
    "# Add row using concat\n",
    "new_row = pd.DataFrame([['Eve', 33, 58000, 'Berlin', 58]], \n",
    "                       columns=df.columns)\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "print(\"\\nAfter concatenating new row:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2117463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column\n",
    "df_dropped_col = df.drop('Salary_k', axis=1)\n",
    "print(\"After dropping 'Salary_k' column:\")\n",
    "print(df_dropped_col)\n",
    "\n",
    "# Drop multiple columns\n",
    "df_dropped_cols = df.drop(['City', 'Salary_k'], axis=1)\n",
    "print(\"\\nAfter dropping multiple columns:\")\n",
    "print(df_dropped_cols)\n",
    "\n",
    "# Drop row\n",
    "df_dropped_row = df.drop(3, axis=0)\n",
    "print(\"\\nAfter dropping row 3:\")\n",
    "print(df_dropped_row)\n",
    "\n",
    "# Drop rows with condition\n",
    "df_filtered = df[df['Age'] >= 30]\n",
    "print(\"\\nKeep only rows where Age >= 30:\")\n",
    "print(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7c1df",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "Real-world data often contains missing values. Pandas provides tools to handle them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4da027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with missing values\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [25, np.nan, 35, 28, np.nan],\n",
    "    'City': ['New York', 'London', None, 'Tokyo', 'Berlin'],\n",
    "    'Salary': [50000, 60000, np.nan, 65000, 58000]\n",
    "})\n",
    "\n",
    "print(\"DataFrame with missing values:\")\n",
    "print(df)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nAny missing values?:\", df.isnull().any().any())\n",
    "\n",
    "# Visualize missing data\n",
    "print(\"\\nMissing data mask:\")\n",
    "print(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2694a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values\n",
    "df_dropped = df.dropna()\n",
    "print(\"After dropping rows with NaN:\")\n",
    "print(df_dropped)\n",
    "\n",
    "# Drop columns with any missing values\n",
    "df_dropped_cols = df.dropna(axis=1)\n",
    "print(\"\\nAfter dropping columns with NaN:\")\n",
    "print(df_dropped_cols)\n",
    "\n",
    "# Drop rows only if all values are missing\n",
    "df_dropped_all = df.dropna(how='all')\n",
    "print(\"\\nAfter dropping rows where all values are NaN:\")\n",
    "print(df_dropped_all)\n",
    "\n",
    "# Drop rows with missing values in specific columns\n",
    "df_dropped_subset = df.dropna(subset=['Age'])\n",
    "print(\"\\nAfter dropping rows with NaN in 'Age':\")\n",
    "print(df_dropped_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7debea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with a constant\n",
    "df_filled = df.fillna(0)\n",
    "print(\"Fill NaN with 0:\")\n",
    "print(df_filled)\n",
    "\n",
    "# Fill with different values per column\n",
    "df_filled_dict = df.fillna({'Age': df['Age'].mean(), \n",
    "                            'City': 'Unknown', \n",
    "                            'Salary': df['Salary'].median()})\n",
    "print(\"\\nFill with different values per column:\")\n",
    "print(df_filled_dict)\n",
    "\n",
    "# Forward fill (propagate last valid observation)\n",
    "df_ffill = df.fillna(method='ffill')\n",
    "print(\"\\nForward fill:\")\n",
    "print(df_ffill)\n",
    "\n",
    "# Backward fill\n",
    "df_bfill = df.fillna(method='bfill')\n",
    "print(\"\\nBackward fill:\")\n",
    "print(df_bfill)\n",
    "\n",
    "# Interpolate (for numerical data)\n",
    "df_interpolated = df.copy()\n",
    "df_interpolated['Age'] = df_interpolated['Age'].interpolate()\n",
    "print(\"\\nInterpolated Age:\")\n",
    "print(df_interpolated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed6c77d",
   "metadata": {},
   "source": [
    "## Sorting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b64aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Charlie', 'Alice', 'Eve', 'Bob', 'David'],\n",
    "    'Age': [35, 25, 32, 30, 28],\n",
    "    'Salary': [55000, 50000, 58000, 60000, 65000]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Sort by single column\n",
    "df_sorted = df.sort_values('Age')\n",
    "print(\"\\nSorted by Age:\")\n",
    "print(df_sorted)\n",
    "\n",
    "# Sort in descending order\n",
    "df_sorted_desc = df.sort_values('Salary', ascending=False)\n",
    "print(\"\\nSorted by Salary (descending):\")\n",
    "print(df_sorted_desc)\n",
    "\n",
    "# Sort by multiple columns\n",
    "df_sorted_multi = df.sort_values(['Age', 'Salary'], ascending=[True, False])\n",
    "print(\"\\nSorted by Age (asc) then Salary (desc):\")\n",
    "print(df_sorted_multi)\n",
    "\n",
    "# Sort by index\n",
    "df_sorted_index = df.sort_index()\n",
    "print(\"\\nSorted by index:\")\n",
    "print(df_sorted_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28717e5f",
   "metadata": {},
   "source": [
    "## Grouping and Aggregation\n",
    "\n",
    "GroupBy allows you to split data into groups and apply functions to each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Department': ['Sales', 'Sales', 'IT', 'IT', 'HR', 'HR', 'Sales'],\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace'],\n",
    "    'Age': [25, 30, 35, 28, 32, 45, 27],\n",
    "    'Salary': [50000, 60000, 55000, 65000, 58000, 52000, 54000]\n",
    "})\n",
    "\n",
    "print(\"Employee DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Group by single column\n",
    "grouped = df.groupby('Department')\n",
    "\n",
    "# Calculate mean per group\n",
    "print(\"\\nMean salary by department:\")\n",
    "print(grouped['Salary'].mean())\n",
    "\n",
    "# Multiple aggregations\n",
    "print(\"\\nMultiple statistics by department:\")\n",
    "print(grouped['Salary'].agg(['mean', 'min', 'max', 'count']))\n",
    "\n",
    "# Group by and aggregate different columns differently\n",
    "print(\"\\nDifferent aggregations per column:\")\n",
    "print(grouped.agg({\n",
    "    'Age': ['mean', 'min', 'max'],\n",
    "    'Salary': ['mean', 'sum']\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f03e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple grouping columns\n",
    "df['Experience'] = ['Junior', 'Senior', 'Senior', 'Junior', 'Senior', 'Senior', 'Junior']\n",
    "\n",
    "print(\"DataFrame with Experience:\")\n",
    "print(df)\n",
    "\n",
    "# Group by multiple columns\n",
    "grouped_multi = df.groupby(['Department', 'Experience'])\n",
    "print(\"\\nMean salary by Department and Experience:\")\n",
    "print(grouped_multi['Salary'].mean())\n",
    "\n",
    "# Reset index to make it a regular DataFrame\n",
    "print(\"\\nWith reset index:\")\n",
    "print(grouped_multi['Salary'].mean().reset_index())\n",
    "\n",
    "# Size of each group\n",
    "print(\"\\nCount of employees per group:\")\n",
    "print(grouped_multi.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32750932",
   "metadata": {},
   "source": [
    "## Merging and Joining DataFrames\n",
    "\n",
    "Combine multiple DataFrames like SQL joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff8446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrames\n",
    "employees = pd.DataFrame({\n",
    "    'EmployeeID': [1, 2, 3, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'DepartmentID': [101, 102, 101, 103]\n",
    "})\n",
    "\n",
    "departments = pd.DataFrame({\n",
    "    'DepartmentID': [101, 102, 103, 104],\n",
    "    'Department': ['Sales', 'IT', 'HR', 'Marketing']\n",
    "})\n",
    "\n",
    "print(\"Employees:\")\n",
    "print(employees)\n",
    "print(\"\\nDepartments:\")\n",
    "print(departments)\n",
    "\n",
    "# Inner join (only matching rows)\n",
    "merged_inner = pd.merge(employees, departments, on='DepartmentID', how='inner')\n",
    "print(\"\\nInner join:\")\n",
    "print(merged_inner)\n",
    "\n",
    "# Left join (all rows from left DataFrame)\n",
    "merged_left = pd.merge(employees, departments, on='DepartmentID', how='left')\n",
    "print(\"\\nLeft join:\")\n",
    "print(merged_left)\n",
    "\n",
    "# Right join\n",
    "merged_right = pd.merge(employees, departments, on='DepartmentID', how='right')\n",
    "print(\"\\nRight join:\")\n",
    "print(merged_right)\n",
    "\n",
    "# Outer join (all rows from both)\n",
    "merged_outer = pd.merge(employees, departments, on='DepartmentID', how='outer')\n",
    "print(\"\\nOuter join:\")\n",
    "print(merged_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ecac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames vertically (stack rows)\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "\n",
    "concatenated = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"\\nConcatenated vertically:\")\n",
    "print(concatenated)\n",
    "\n",
    "# Concatenate horizontally (side by side)\n",
    "df3 = pd.DataFrame({'C': [9, 10], 'D': [11, 12]})\n",
    "concatenated_h = pd.concat([df1, df3], axis=1)\n",
    "print(\"\\nConcatenated horizontally:\")\n",
    "print(concatenated_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e84bf0a",
   "metadata": {},
   "source": [
    "## Pivot Tables and Reshaping\n",
    "\n",
    "Transform data between wide and long formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10e9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "sales = pd.DataFrame({\n",
    "    'Date': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02', '2024-01-03', '2024-01-03'],\n",
    "    'Product': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'Sales': [100, 150, 120, 180, 110, 160],\n",
    "    'Region': ['East', 'East', 'West', 'West', 'East', 'East']\n",
    "})\n",
    "\n",
    "print(\"Sales data:\")\n",
    "print(sales)\n",
    "\n",
    "# Create pivot table\n",
    "pivot = sales.pivot_table(values='Sales', \n",
    "                          index='Date', \n",
    "                          columns='Product', \n",
    "                          aggfunc='sum')\n",
    "print(\"\\nPivot table (Sales by Date and Product):\")\n",
    "print(pivot)\n",
    "\n",
    "# Pivot with multiple values\n",
    "pivot_multi = sales.pivot_table(values='Sales', \n",
    "                                index='Date', \n",
    "                                columns='Product', \n",
    "                                aggfunc=['sum', 'mean'])\n",
    "print(\"\\nPivot with multiple aggregations:\")\n",
    "print(pivot_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c50a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt (wide to long format)\n",
    "df_wide = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Math': [90, 85, 95],\n",
    "    'English': [88, 92, 89]\n",
    "})\n",
    "\n",
    "print(\"Wide format:\")\n",
    "print(df_wide)\n",
    "\n",
    "df_long = pd.melt(df_wide, \n",
    "                  id_vars=['Name'], \n",
    "                  value_vars=['Math', 'English'],\n",
    "                  var_name='Subject', \n",
    "                  value_name='Score')\n",
    "print(\"\\nLong format (melted):\")\n",
    "print(df_long)\n",
    "\n",
    "# Pivot (long to wide format)\n",
    "df_wide_again = df_long.pivot(index='Name', columns='Subject', values='Score')\n",
    "print(\"\\nBack to wide format:\")\n",
    "print(df_wide_again)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a711588e",
   "metadata": {},
   "source": [
    "## Reading and Writing Data\n",
    "\n",
    "Pandas can read/write data from/to various formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc69b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 28],\n",
    "    'City': ['New York', 'London', 'Paris', 'Tokyo'],\n",
    "    'Salary': [50000, 60000, 55000, 65000]\n",
    "})\n",
    "\n",
    "# Write to CSV\n",
    "df.to_csv('employees.csv', index=False)\n",
    "print(\"Written to employees.csv\")\n",
    "\n",
    "# Read from CSV\n",
    "df_from_csv = pd.read_csv('employees.csv')\n",
    "print(\"\\nRead from CSV:\")\n",
    "print(df_from_csv)\n",
    "\n",
    "# Write to Excel (requires openpyxl)\n",
    "# df.to_excel('employees.xlsx', index=False, sheet_name='Employees')\n",
    "\n",
    "# Read from Excel\n",
    "# df_from_excel = pd.read_excel('employees.xlsx', sheet_name='Employees')\n",
    "\n",
    "# Write to JSON\n",
    "df.to_json('employees.json', orient='records', indent=2)\n",
    "print(\"\\nWritten to employees.json\")\n",
    "\n",
    "# Read from JSON\n",
    "df_from_json = pd.read_json('employees.json')\n",
    "print(\"\\nRead from JSON:\")\n",
    "print(df_from_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a13d385",
   "metadata": {},
   "source": [
    "## String Operations\n",
    "\n",
    "Pandas provides powerful string manipulation methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6689fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with string data\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['alice smith', 'BOB JONES', 'Charlie Brown', 'david LEE'],\n",
    "    'Email': ['alice@example.com', 'BOB@EXAMPLE.COM', 'charlie@test.org', 'david@sample.net']\n",
    "})\n",
    "\n",
    "print(\"Original:\")\n",
    "print(df)\n",
    "\n",
    "# Convert to lowercase\n",
    "df['Name_lower'] = df['Name'].str.lower()\n",
    "\n",
    "# Convert to uppercase\n",
    "df['Name_upper'] = df['Name'].str.upper()\n",
    "\n",
    "# Title case\n",
    "df['Name_title'] = df['Name'].str.title()\n",
    "\n",
    "print(\"\\nWith case conversions:\")\n",
    "print(df[['Name', 'Name_lower', 'Name_upper', 'Name_title']])\n",
    "\n",
    "# Extract domain from email\n",
    "df['Domain'] = df['Email'].str.split('@').str[1]\n",
    "\n",
    "# Check if contains substring\n",
    "df['Has_example'] = df['Email'].str.contains('example')\n",
    "\n",
    "# Replace text\n",
    "df['Email_masked'] = df['Email'].str.replace('@', ' [at] ')\n",
    "\n",
    "print(\"\\nWith string operations:\")\n",
    "print(df[['Email', 'Domain', 'Has_example', 'Email_masked']])\n",
    "\n",
    "# String length\n",
    "df['Name_length'] = df['Name'].str.len()\n",
    "\n",
    "# Strip whitespace\n",
    "df['Name_stripped'] = df['Name'].str.strip()\n",
    "\n",
    "print(\"\\nString length and stripped:\")\n",
    "print(df[['Name', 'Name_length', 'Name_stripped']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65a99c",
   "metadata": {},
   "source": [
    "## Date and Time Operations\n",
    "\n",
    "Pandas has excellent support for working with dates and times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with date strings\n",
    "df = pd.DataFrame({\n",
    "    'Date': ['2024-01-15', '2024-02-20', '2024-03-25', '2024-04-30'],\n",
    "    'Sales': [1000, 1500, 1200, 1800]\n",
    "})\n",
    "\n",
    "print(\"Original:\")\n",
    "print(df)\n",
    "print(\"\\nDate dtype:\", df['Date'].dtype)\n",
    "\n",
    "# Convert to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(\"\\nAfter conversion:\")\n",
    "print(df)\n",
    "print(\"Date dtype:\", df['Date'].dtype)\n",
    "\n",
    "# Extract date components\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "df['DayName'] = df['Date'].dt.day_name()\n",
    "df['MonthName'] = df['Date'].dt.month_name()\n",
    "\n",
    "print(\"\\nWith extracted components:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b95942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range\n",
    "date_range = pd.date_range(start='2024-01-01', end='2024-01-10', freq='D')\n",
    "print(\"Date range:\")\n",
    "print(date_range)\n",
    "\n",
    "# Create DataFrame with date range\n",
    "df_dates = pd.DataFrame({\n",
    "    'Date': pd.date_range('2024-01-01', periods=10, freq='D'),\n",
    "    'Value': np.random.randint(100, 200, 10)\n",
    "})\n",
    "\n",
    "print(\"\\nDataFrame with date range:\")\n",
    "print(df_dates)\n",
    "\n",
    "# Set date as index\n",
    "df_dates.set_index('Date', inplace=True)\n",
    "print(\"\\nWith date as index:\")\n",
    "print(df_dates)\n",
    "\n",
    "# Select by date\n",
    "print(\"\\nData for 2024-01-05:\")\n",
    "print(df_dates.loc['2024-01-05'])\n",
    "\n",
    "# Date arithmetic\n",
    "print(\"\\nDates + 7 days:\")\n",
    "print(df_dates.index + pd.Timedelta(days=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5fea6",
   "metadata": {},
   "source": [
    "## Practical Example: Sales Data Analysis\n",
    "\n",
    "Let's analyze a realistic sales dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d6bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2024-01-01', periods=100, freq='D')\n",
    "products = ['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard']\n",
    "regions = ['North', 'South', 'East', 'West']\n",
    "\n",
    "sales_data = pd.DataFrame({\n",
    "    'Date': np.random.choice(dates, 200),\n",
    "    'Product': np.random.choice(products, 200),\n",
    "    'Region': np.random.choice(regions, 200),\n",
    "    'Quantity': np.random.randint(1, 20, 200),\n",
    "    'Price': np.random.randint(100, 2000, 200)\n",
    "})\n",
    "\n",
    "sales_data['Revenue'] = sales_data['Quantity'] * sales_data['Price']\n",
    "sales_data = sales_data.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "print(\"Sales data (first 10 rows):\")\n",
    "print(sales_data.head(10))\n",
    "\n",
    "print(\"\\nDataset info:\")\n",
    "print(f\"Shape: {sales_data.shape}\")\n",
    "print(f\"Columns: {sales_data.columns.tolist()}\")\n",
    "print(f\"\\nTotal revenue: ${sales_data['Revenue'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41524685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 1: Revenue by product\n",
    "revenue_by_product = sales_data.groupby('Product')['Revenue'].sum().sort_values(ascending=False)\n",
    "print(\"Revenue by product:\")\n",
    "print(revenue_by_product)\n",
    "\n",
    "# Analysis 2: Average price and quantity by product\n",
    "product_stats = sales_data.groupby('Product').agg({\n",
    "    'Price': 'mean',\n",
    "    'Quantity': 'mean',\n",
    "    'Revenue': 'sum'\n",
    "}).round(2)\n",
    "print(\"\\nProduct statistics:\")\n",
    "print(product_stats)\n",
    "\n",
    "# Analysis 3: Best performing region\n",
    "revenue_by_region = sales_data.groupby('Region')['Revenue'].sum().sort_values(ascending=False)\n",
    "print(\"\\nRevenue by region:\")\n",
    "print(revenue_by_region)\n",
    "\n",
    "# Analysis 4: Monthly revenue\n",
    "sales_data['Month'] = pd.to_datetime(sales_data['Date']).dt.to_period('M')\n",
    "monthly_revenue = sales_data.groupby('Month')['Revenue'].sum()\n",
    "print(\"\\nMonthly revenue:\")\n",
    "print(monthly_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis 5: Top 5 days by revenue\n",
    "top_days = sales_data.groupby('Date')['Revenue'].sum().nlargest(5)\n",
    "print(\"Top 5 days by revenue:\")\n",
    "print(top_days)\n",
    "\n",
    "# Analysis 6: Product-Region performance matrix\n",
    "pivot_table = sales_data.pivot_table(\n",
    "    values='Revenue',\n",
    "    index='Product',\n",
    "    columns='Region',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "print(\"\\nRevenue by Product and Region:\")\n",
    "print(pivot_table)\n",
    "\n",
    "# Analysis 7: Best selling product per region\n",
    "best_per_region = sales_data.groupby(['Region', 'Product'])['Revenue'].sum().reset_index()\n",
    "best_per_region = best_per_region.loc[best_per_region.groupby('Region')['Revenue'].idxmax()]\n",
    "print(\"\\nBest selling product per region:\")\n",
    "print(best_per_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711a9fbf",
   "metadata": {},
   "source": [
    "## Basic Visualization\n",
    "\n",
    "Pandas has built-in plotting capabilities using Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d487d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create sample data\n",
    "df = pd.DataFrame({\n",
    "    'Month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'],\n",
    "    'Sales': [1000, 1500, 1200, 1800, 2100, 1900],\n",
    "    'Expenses': [800, 900, 850, 950, 1100, 1000]\n",
    "})\n",
    "\n",
    "# Line plot\n",
    "df.plot(x='Month', y=['Sales', 'Expenses'], kind='line', figsize=(10, 5))\n",
    "plt.title('Sales vs Expenses')\n",
    "plt.ylabel('Amount ($)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Bar plot\n",
    "df.plot(x='Month', y='Sales', kind='bar', figsize=(10, 5), color='skyblue')\n",
    "plt.title('Monthly Sales')\n",
    "plt.ylabel('Sales ($)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Multiple columns bar plot\n",
    "df.plot(x='Month', y=['Sales', 'Expenses'], kind='bar', figsize=(10, 5))\n",
    "plt.title('Sales and Expenses by Month')\n",
    "plt.ylabel('Amount ($)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a6714",
   "metadata": {},
   "source": [
    "## Common Pandas Operations Cheat Sheet\n",
    "\n",
    "### Selection:\n",
    "- `df['column']` - Select single column\n",
    "- `df[['col1', 'col2']]` - Select multiple columns\n",
    "- `df.iloc[0]` - Select by position\n",
    "- `df.loc[0, 'col']` - Select by label\n",
    "- `df[df['col'] > value]` - Filter rows\n",
    "\n",
    "### Aggregation:\n",
    "- `df.groupby('col').agg()` - Group and aggregate\n",
    "- `df.sum()`, `df.mean()`, `df.count()` - Statistics\n",
    "- `df.describe()` - Summary statistics\n",
    "\n",
    "### Transformation:\n",
    "- `df.sort_values('col')` - Sort\n",
    "- `df.drop('col', axis=1)` - Drop column\n",
    "- `df.fillna(value)` - Fill missing values\n",
    "- `df.dropna()` - Drop missing values\n",
    "\n",
    "### Merging:\n",
    "- `pd.merge(df1, df2, on='key')` - Join DataFrames\n",
    "- `pd.concat([df1, df2])` - Concatenate\n",
    "- `df.pivot_table()` - Create pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b11d6c",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Practice with these exercises:\n",
    "\n",
    "1. Create a DataFrame with student names, grades for 3 subjects, and calculate average grade\n",
    "2. Load a CSV file and find the top 5 rows with the highest values in a specific column\n",
    "3. Group data by category and calculate sum, mean, and count for each group\n",
    "4. Handle missing values by filling them with the column mean\n",
    "5. Merge two DataFrames (students and their courses) using a common ID\n",
    "6. Create a pivot table showing average grades by student and subject\n",
    "7. Extract year, month, and day from a date column\n",
    "8. Find duplicate rows and remove them\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a183d3f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Pandas is essential for:\n",
    "- Data manipulation and cleaning\n",
    "- Exploratory data analysis\n",
    "- Data preparation for machine learning\n",
    "- Working with structured data\n",
    "\n",
    "**Key Takeaways:**\n",
    "- DataFrame and Series are the core data structures\n",
    "- Powerful selection, filtering, and indexing capabilities\n",
    "- GroupBy enables split-apply-combine operations\n",
    "- Easy handling of missing data\n",
    "- Built-in support for merging, joining, and reshaping\n",
    "- Excellent time series functionality\n",
    "- Direct integration with visualization libraries\n",
    "\n",
    "**Next Steps:**\n",
    "- Practice with real datasets (Kaggle, UCI ML Repository)\n",
    "- Learn data visualization with Matplotlib and Seaborn\n",
    "- Explore advanced pandas features (MultiIndex, window functions)\n",
    "- Study data cleaning and preprocessing techniques\n",
    "- Combine with NumPy for numerical operations"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
